"""
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–¥–∞–Ω–∏–π —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Gemini API.
–ê–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ Word –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ HTML —Ç–µ–∫—Å—Ç–æ–≤.

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–≥–æ Gemini API
- –†–æ—Ç–∞—Ü–∏—è 6 API –∫–ª—é—á–µ–π –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∫–≤–æ—Ç
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–µ—Ä–∂–∫–∏ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤
- –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –ø–æ–ø—ã—Ç–∫–∏
- –ë–∏–Ω–∞—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: –∑–∞—á—Ç–µ–Ω–æ/–Ω–µ –∑–∞—á—Ç–µ–Ω–æ
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ result.txt –∏ –∏—Ç–æ–≥–æ–≤—É—é –≤–µ–¥–æ–º–æ—Å—Ç—å
"""

import asyncio
import json
import logging
import os
import threading
from threading import Thread
from typing import Callable, List
import time
import random
import re

import aiofiles
import pandas as pd
from bs4 import BeautifulSoup
from colorama import init
from tenacity import retry, stop_after_attempt, wait_fixed, retry_if_exception_type
from tqdm import tqdm
from urllib.parse import urlparse

# –ò–º–ø–æ—Ä—Ç Gemini API
from google import genai
from google.genai import types

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è colorama –¥–ª—è —Ü–≤–µ—Ç–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
init(autoreset=True)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# API –∫–ª—é—á–∏ Gemini –¥–ª—è —Ä–æ—Ç–∞—Ü–∏–∏
API_KEYS = [
    "AIzaSyBZERjXBrLTMniOGnajrIrzoZvBkcx8_dE",
    "AIzaSyBVyS1pW5X7WW6qKLbd4wZxGYy4oLV5YGA",
    "AIzaSyDNRbu7_VJmp1wwY_9Ziz8VqXRQo7CNYJo",
    "AIzaSyB3JtO6koAQZBsu7_S3jgryn81asEHSQqQ",
    "AIzaSyBS_L7_FwnFhK5M3GglsJc1jaUVS4Uv_T0",
    "AIzaSyBj_YDJXk3QnhIH8FdIZkkPOnxNfirSyWY",
    "AIzaSyBP-sSpfUVTAWXd-prxEvdbBeLCaw_NCsk",
    "AIzaSyC6exCJDufHqzSj10vMGAJ0GgIT4WnmWQA", 
    "AIzaSyATbFpgBVoYmxr0oaaRI9tEstkXM5aHmwY",
    "AIzaSyDNyyAGQVSoqw1gDov03iRNtx9-9vH28iI",
    "AIzaSyDDzd5N3Z_be3OMhsPQGhF4YHc9bM5RAMo",
    "AIzaSyAWQjDRCIwGfn74jfaNaZjSUBsvAu9hpKw"
]

# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π Gemini –¥–ª—è –ø–µ—Ä–µ–±–æ—Ä–∞
AVAILABLE_MODELS = [
    "gemini-2.0-flash",
    "gemini-2.0-flash-lite"
]

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–¥–µ—Ä–∂–µ–∫ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –∫–≤–æ—Ç
MIN_DELAY = 10.0  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—Å–µ–∫—É–Ω–¥—ã)
MAX_DELAY = 20.0  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—Å–µ–∫—É–Ω–¥—ã)
REQUEST_TIMEOUT = 120  # –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ (—Å–µ–∫—É–Ω–¥—ã)


class GeminiClient:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Gemini API —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º–∏ –∑–∞–¥–µ—Ä–∂–∫–∞–º–∏ –∏ —Ä–æ—Ç–∞—Ü–∏–µ–π –∫–ª—é—á–µ–π."""

    def __init__(self, api_key: str = None):
        self.api_keys = API_KEYS.copy()
        self.current_key_index = 0
        self.api_key = api_key or self.api_keys[self.current_key_index]
        self._http_options = self._build_http_options()
        self.client = genai.Client(api_key=self.api_key, http_options=self._http_options)
        self.last_request_time = 0
        self.key_usage_count = {key: 0 for key in self.api_keys}

    @staticmethod
    def _build_http_options():
        """–°–æ–±–∏—Ä–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ HTTP —Å —É—á—ë—Ç–æ–º –ø—Ä–æ–∫—Å–∏ –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è."""

        proxies = {}

        raw_proxy = (
            os.environ.get("HTTPS_PROXY")
            or os.environ.get("https_proxy")
            or os.environ.get("HTTP_PROXY")
            or os.environ.get("http_proxy")
        )

        if not raw_proxy:
            host = os.environ.get("PROXY_HOST")
            port = os.environ.get("PROXY_PORT")
            if host and port:
                user = os.environ.get("PROXY_USER")
                password = os.environ.get("PROXY_PASS")
                credentials = f"{user}:{password}@" if user and password else ""
                raw_proxy = f"socks5h://{credentials}{host}:{port}"

        if raw_proxy:
            parsed = urlparse(raw_proxy)
            scheme = parsed.scheme.lower()
            if not scheme:
                raw_proxy = f"socks5h://{raw_proxy}"
            elif scheme in {"http", "https"}:
                raw_proxy = raw_proxy.replace(f"{parsed.scheme}://", "socks5h://", 1)

            proxies = {"http": raw_proxy, "https": raw_proxy}
            logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è SOCKS5 –ø—Ä–æ–∫—Å–∏ –¥–ª—è Gemini API: %s", raw_proxy)

        if not proxies:
            return None

        client_args = {
            "proxies": proxies,
            "http2": False,
        }

        return types.HttpOptions(
            client_args=client_args,
            async_client_args=client_args,
        )
        
    async def _wait_for_rate_limit(self):
        """–û–∂–∏–¥–∞–Ω–∏–µ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤ API."""
        current_time = time.time()
        time_since_last_request = current_time - self.last_request_time
        
        if time_since_last_request < MIN_DELAY:
            wait_time = MIN_DELAY - time_since_last_request + random.uniform(0, MAX_DELAY - MIN_DELAY)
            logger.debug(f"–û–∂–∏–¥–∞–Ω–∏–µ {wait_time:.2f} —Å–µ–∫—É–Ω–¥ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤ API...")
            await asyncio.sleep(wait_time)
        
        self.last_request_time = time.time()
    
    def _rotate_api_key(self):
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π API –∫–ª—é—á."""
        self.current_key_index = (self.current_key_index + 1) % len(self.api_keys)
        self.api_key = self.api_keys[self.current_key_index]
        self.client = genai.Client(api_key=self.api_key, http_options=self._http_options)
        logger.info(f"–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ API –∫–ª—é—á {self.current_key_index + 1}/{len(self.api_keys)}")
    
    async def _handle_quota_error(self, error_msg: str, attempt: int) -> int:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∫–≤–æ—Ç —Å —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π –∏ —Ä–æ—Ç–∞—Ü–∏–µ–π –∫–ª—é—á–µ–π."""
        if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å –∫–ª—é—á
            self._rotate_api_key()
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ
            import re
            retry_match = re.search(r'retry in (\d+(?:\.\d+)?)s', error_msg)
            if retry_match:
                wait_time = float(retry_match.group(1))
                # –î–æ–±–∞–≤–ª—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                wait_time += 10
            else:
                # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞: 60s, 120s, 240s...
                wait_time = 60 * (2 ** (attempt - 1))
            
            logger.warning(f"üîÑ –ü—Ä–µ–≤—ã—à–µ–Ω–∞ –∫–≤–æ—Ç–∞ API. –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ –∫–ª—é—á {self.current_key_index + 1}/{len(self.api_keys)} –∏ –æ–∂–∏–¥–∞–Ω–∏–µ {wait_time:.1f} —Å–µ–∫—É–Ω–¥...")
            await asyncio.sleep(wait_time)
            return attempt + 1
        return attempt
    
    async def generate_content(self, text: str, model: str = None) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å –ø–æ–º–æ—â—å—é Gemini API.
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            model: –ú–æ–¥–µ–ª—å –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–µ—Ä–≤–∞—è –∏–∑ —Å–ø–∏—Å–∫–∞)
            
        Returns:
            –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        if model is None:
            model = AVAILABLE_MODELS[0]
            
        await self._wait_for_rate_limit()
        
        try:
            logger.debug(f"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ –º–æ–¥–µ–ª–∏ {model} —Å –∫–ª—é—á–æ–º {self.current_key_index + 1}")
            
            contents = [
                types.Content(
                    role="user",
                    parts=[
                        types.Part.from_text(text=text),
                    ],
                ),
            ]
            
            generate_content_config = types.GenerateContentConfig(
                temperature=0.1,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
                max_output_tokens=8192,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
            )
            
            # –°–æ–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç
            response = self.client.models.generate_content(
                model=model,
                contents=contents,
                config=generate_content_config,
            )

            # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞
            full_response = getattr(response, "text", "") or ""
            if not full_response and getattr(response, "candidates", None):
                parts: list[str] = []
                for candidate in response.candidates:
                    content = getattr(candidate, "content", None)
                    if not content:
                        continue
                    for part in getattr(content, "parts", []):
                        text_part = getattr(part, "text", None)
                        if text_part:
                            parts.append(text_part)
                full_response = "".join(parts)

            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–ª—é—á–∞
            self.key_usage_count[self.api_key] += 1
            logger.debug(
                "–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ %s (–∫–ª—é—á %s, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–π: %s)",
                model,
                self.current_key_index + 1,
                self.key_usage_count[self.api_key],
            )
            return full_response.strip()
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ –º–æ–¥–µ–ª–∏ {model} —Å –∫–ª—é—á–æ–º {self.current_key_index + 1}: {e}")
            raise


async def extract_text_from_html(html_path: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ HTML —Ñ–∞–π–ª–∞.
    """
    try:
        async with aiofiles.open(html_path, 'r', encoding='utf-8') as f:
            html_content = await f.read()
        
        soup = BeautifulSoup(html_content, 'html.parser')
        text = soup.get_text(separator=' ', strip=True)
        return text
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ HTML {html_path}: {e}")
        return ""


async def extract_text_from_word(word_path: str) -> str:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ Word –¥–æ–∫—É–º–µ–Ω—Ç–∞.
    """
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å python-docx –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        try:
            from docx import Document
            doc = Document(word_path)
            text_parts = []
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    text_parts.append(paragraph.text.strip())
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ —Ç–∞–±–ª–∏—Ü
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        if cell.text.strip():
                            text_parts.append(cell.text.strip())
            
            full_text = '\n'.join(text_parts)
            
            # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ —à–∞–±–ª–æ–Ω
            if len(full_text.strip()) < 100:
                logger.warning(f"–í–æ–∑–º–æ–∂–Ω–æ, —ç—Ç–æ —à–∞–±–ª–æ–Ω –∏–ª–∏ –ø—É—Å—Ç–æ–π –¥–æ–∫—É–º–µ–Ω—Ç: {word_path}")
                return full_text
            
            return full_text
            
        except ImportError:
            logger.warning("python-docx –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ")
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ python-docx: {e}, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ")
        
        # –ë–∞–∑–æ–≤–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∫–∞–∫ fallback
        async with aiofiles.open(word_path, 'rb') as f:
            content = await f.read()
        
        # –ë–∞–∑–æ–≤–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
        text = content.decode('utf-8', errors='ignore')
        # –û—á–∏—Å—Ç–∫–∞ –æ—Ç —Å–ª—É–∂–µ–±–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ Word
        text = re.sub(r'[^\w\s\u0400-\u04FF.,!?;:()\-]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ Word {word_path}: {e}")
        return ""


async def extract_text_from_pdf(pdf_path: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ PDF –¥–æ–∫—É–º–µ–Ω—Ç–∞.

    –ü–æ—Ä—è–¥–æ–∫ –ø–æ–ø—ã—Ç–æ–∫:
    1) PyPDF2 ‚Äî –ª—ë–≥–∫–∏–π –∏ –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –±–∏–Ω–∞—Ä–Ω–∏–∫–æ–≤;
    2) –§–æ–ª–±—ç–∫: –¥–≤–æ–∏—á–Ω–æ–µ —á—Ç–µ–Ω–∏–µ —Å –≥—Ä—É–±–æ–π –æ—á–∏—Å—Ç–∫–æ–π (–Ω–∞ —Å–ª—É—á–∞–π –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫).
    """
    try:
        try:
            import PyPDF2  # noqa: WPS433
            text_parts: list[str] = []
            with open(pdf_path, 'rb') as fh:
                reader = PyPDF2.PdfReader(fh)
                for page in reader.pages:
                    try:
                        page_text = page.extract_text() or ""
                    except Exception:
                        page_text = ""
                    if page_text.strip():
                        text_parts.append(page_text)
            text = "\n".join(text_parts).strip()
            return text
        except ImportError:
            logger.warning("PyPDF2 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –±–∞–∑–æ–≤–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ PDF")

        # –§–æ–ª–±—ç–∫: —á–∏—Ç–∞–µ–º –∫–∞–∫ —Ç–µ–∫—Å—Ç —Å –¥–æ–ø. –æ—á–∏—Å—Ç–∫–æ–π (–∫–∞—á–µ—Å—Ç–≤–æ –Ω–∏–∂–µ)
        async with aiofiles.open(pdf_path, 'rb') as f:
            content = await f.read()
        text = content.decode('utf-8', errors='ignore')
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF {pdf_path}: {e}")
        return ""


async def answer(client: GeminiClient, text: str, prompt: str = '', limit: int = 60,
                 models: list = None) -> str | None:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏ Gemini –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç.
    –ü–µ—Ä–µ–±–∏—Ä–∞–µ—Ç –º–æ–¥–µ–ª–∏ –∏–∑ —Å–ø–∏—Å–∫–∞, –ø–æ–∫–∞ –Ω–µ –ø–æ–ª—É—á–∏—Ç –≤–∞–ª–∏–¥–Ω—ã–π –æ—Ç–≤–µ—Ç.
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–≤–æ—Ç—ã —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏.
    """
    if models is None:
        models = AVAILABLE_MODELS.copy()

    for model in models:
        attempt = 1
        max_attempts = 10  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–≤–æ—Ç
        
        while attempt <= max_attempts:
            try:
                logger.info(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_attempts} —Å –º–æ–¥–µ–ª—å—é {model}")
                response = await client.generate_content(f"{prompt}\n{text}", model)
                if response:
                    # –£–¥–∞–ª—è–µ–º –∞–ª—Ñ–∞–≤–∏—Ç–Ω–æ-—Ü–∏—Ñ—Ä–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
                    clear_text = re.sub(r"[A-Za-z0-9]", "", response)
                    clear_text = re.sub(r'\s+', ' ', clear_text.strip())
                    if len(clear_text) > limit:
                        logger.info(f"–ü–æ–ª—É—á–µ–Ω –≤–∞–ª–∏–¥–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏ {model}.")
                        return response.strip()
                    else:
                        logger.warning(f"–û—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π: {len(clear_text)} —Å–∏–º–≤–æ–ª–æ–≤.")
                        if attempt < max_attempts:
                            await asyncio.sleep(5)
                            attempt += 1
                            continue
            except Exception as e:
                error_msg = str(e)
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –º–æ–¥–µ–ª—å—é {model}, –ø–æ–ø—ã—Ç–∫–∞ {attempt}/{max_attempts}: {e}")
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∫–≤–æ—Ç
                if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg:
                    attempt = await client._handle_quota_error(error_msg, attempt)
                    if attempt > max_attempts:
                        logger.error(f"–ü—Ä–µ–≤—ã—à–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –¥–ª—è –º–æ–¥–µ–ª–∏ {model}")
                        break
                    continue
                elif "404" in error_msg or "NOT_FOUND" in error_msg:
                    logger.warning(f"–ú–æ–¥–µ–ª—å {model} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–π –º–æ–¥–µ–ª–∏...")
                    break
                else:
                    if attempt < max_attempts:
                        await asyncio.sleep(5)
                        attempt += 1
                        continue
                    else:
                        logger.error(f"–ú–æ–¥–µ–ª—å {model} –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å –Ω–µ—É–¥–∞—á–µ–π –ø–æ—Å–ª–µ {max_attempts} –ø–æ–ø—ã—Ç–æ–∫")
                        break

    logger.error("–í—Å–µ –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å –Ω–µ—É–¥–∞—á–µ–π.")
    return None


def extract_binary_result(msg: str) -> dict | None:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –±–∏–Ω–∞—Ä–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–∑–∞—á—Ç–µ–Ω–æ/–Ω–µ –∑–∞—á—Ç–µ–Ω–æ) –∏–∑ –æ—Ç–≤–µ—Ç–∞ AI.
    """
    try:
        logger.debug("–ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –±–∏–Ω–∞—Ä–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞...")
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        json_match = re.search(r'\{[^{}]*"result"[^{}]*\}', msg, re.DOTALL)
        if json_match:
            try:
                json_str = json_match.group(0)
                data = json.loads(json_str)
                result = data.get('result', '–Ω–µ –∑–∞—á—Ç–µ–Ω–æ').lower()
                comment = data.get('comment', '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω')
                return {
                    "result": result,
                    "comment": comment
                }
            except json.JSONDecodeError:
                logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
        
        # Fallback: –∏—â–µ–º –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        msg_lower = msg.lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ" –ü–ï–†–ï–î "–∑–∞—á—Ç–µ–Ω–æ", —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π
        if "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ" in msg_lower or "–Ω–µ–∑–∞—á–µ—Ç" in msg_lower or "–Ω–µ –∑–∞—Å—á–∏—Ç–∞–Ω–æ" in msg_lower:
            result = "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ"
        elif "–∑–∞—á—Ç–µ–Ω–æ" in msg_lower or "–∑–∞—á–µ—Ç" in msg_lower or "–∑–∞—Å—á–∏—Ç–∞–Ω–æ" in msg_lower:
            result = "–∑–∞—á—Ç–µ–Ω–æ"
        else:
            result = "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
        comment = msg
        if "–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π:" in msg_lower:
            comment = msg.split("–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π:")[-1].strip()
        elif "comment:" in msg_lower:
            comment = msg.split("comment:")[-1].strip()
        
        # –ï—Å–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, –æ–±—Ä–µ–∑–∞–µ–º
        if len(comment) > 500:
            comment = comment[:500] + "..."
        
        return {
            "result": result,
            "comment": comment
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –±–∏–Ω–∞—Ä–Ω–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {e}")
        return {
            "result": "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ",
            "comment": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –æ—Ç–≤–µ—Ç–∞"
        }


async def check_ai_generation(client: GeminiClient, text: str, models: list = None) -> dict | None:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞–±–æ—Ç—É –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.
    """
    if models is None:
        models = AVAILABLE_MODELS.copy()

    logger.info("–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...")

    prompt = f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –¥–µ—Ç–µ–∫—Ü–∏–∏ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.  
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç–æ–≥–æ, —á—Ç–æ –æ–Ω –±—ã–ª —Å–æ–∑–¥–∞–Ω —Å –ø–æ–º–æ—â—å—é –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞.

–¢–ï–ö–°–¢ –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
{text}

–û–¶–ï–ù–ò –¢–û–õ–¨–ö–û –û–ß–ï–í–ò–î–ù–´–ï –°–õ–£–ß–ê–ò AI-–ì–ï–ù–ï–†–ê–¶–ò–ò.

–ü–†–ò–ó–ù–ê–ö–ò AI-–ì–ï–ù–ï–†–ê–¶–ò–ò:
1. –¢–µ–∫—Å—Ç –Ω–∞–ø–∏—Å–∞–Ω —ç–Ω—Ü–∏–∫–ª–æ–ø–µ–¥–∏—á–µ—Å–∫–∏–º, –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–º –∏–ª–∏ —à–∞–±–ª–æ–Ω–Ω—ã–º —Å—Ç–∏–ª–µ–º, –±–µ–∑ –ª–∏—á–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π.
2. –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –∫–ª–∏—à–µ ChatGPT-–ø–æ–¥–æ–±–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤: ¬´–≤ –∑–∞–∫–ª—é—á–µ–Ω–∏–µ¬ª, ¬´—Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º¬ª, ¬´–≤–∞–∂–Ω–æ –æ—Ç–º–µ—Ç–∏—Ç—å¬ª, ¬´–ø–æ–≤—ã—à–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏¬ª –∏ —Ç.–ø.
3. –í —Ç–µ–∫—Å—Ç–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ—à–∏–±–∫–∏, –ª–∏—á–Ω—ã–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è, –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –∏–ª–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–µ—á–∏.
4. –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –æ–¥–Ω–æ—Ç–∏–ø–Ω—ã –ø–æ –¥–ª–∏–Ω–µ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ, –Ω–µ—Ç —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–∫—Ä–∞—Å–∫–∏.
5. –¢–µ–∫—Å—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –æ–±–æ–±—â–µ–Ω–∏–π, –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤, —Ñ–∞–∫—Ç–æ–≤ –∏–ª–∏ –ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫.

–ü–†–ê–í–ò–õ–ê:
‚Äî –ï—Å–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—á–µ–≤–∏–¥–Ω—ã –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –ø—É–Ω–∫—Ç–∞–º, —É–∫–∞–∂–∏ ai_detected: true.  
‚Äî –ï—Å–ª–∏ –µ—Å—Ç—å —Å–æ–º–Ω–µ–Ω–∏—è, –≤—Å–µ–≥–¥–∞ –≤—ã–±–∏—Ä–∞–π ai_detected: false.  
‚Äî –ù–µ —Å—á–∏—Ç–∞–π AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –ø—Ä–æ—Å—Ç–æ –≥—Ä–∞–º–æ—Ç–Ω—ã–π –∏–ª–∏ –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π —Ç–µ–∫—Å—Ç ‚Äî —Ç–æ–ª—å–∫–æ —è–≤–Ω–æ —à–∞–±–ª–æ–Ω–Ω—ã–µ —Å–ª—É—á–∞–∏.

–§–û–†–ú–ê–¢ –í–´–í–û–î–ê:
{{
  "ai_detected": true –∏–ª–∏ false,
  "confidence": "–Ω–∏–∑–∫–∞—è", "—Å—Ä–µ–¥–Ω—è—è" –∏–ª–∏ "–≤—ã—Å–æ–∫–∞—è",
  "reasons": ["—Å–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"],
  "comment": "–¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å—Ç–∏–ª—è –∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è"
}}

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
"""

    response = await answer(client, text=text, prompt=prompt, models=models)
    if response:
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ JSON –≤ –æ—Ç–≤–µ—Ç–µ
            json_match = re.search(r'\{[^{}]*"ai_detected"[^{}]*\}', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                data = json.loads(json_str)
                return {
                    "ai_detected": data.get('ai_detected', False),
                    "confidence": data.get('confidence', '–Ω–∏–∑–∫–∞—è'),
                    "reasons": data.get('reasons', []),
                    "comment": data.get('comment', '–ê–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω')
                }
        except json.JSONDecodeError:
            logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç–≤–µ—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ AI")
    
    return None


async def get_binary_evaluation(
    client: GeminiClient,
    text: str,
    template_text: str,
    models: list = None,
    room_prompt: str = "",
    ai_confidence: str | None = None,
    ai_check_enabled: bool = True,
) -> dict | None:
    """
    –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –±–∏–Ω–∞—Ä–Ω—É—é –æ—Ü–µ–Ω–∫—É —É –º–æ–¥–µ–ª–∏.
    """
    if models is None:
        models = AVAILABLE_MODELS.copy()

    logger.info("–ó–∞–ø—Ä–æ—Å –±–∏–Ω–∞—Ä–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ —É –º–æ–¥–µ–ª–∏...")

    # –ü—Ä–æ–º–ø—Ç –¥–ª—è —Ä–µ–∂–∏–º–∞ –ë–ï–ó AI –ø—Ä–æ–≤–µ—Ä–∫–∏ - —Ñ–æ–∫—É—Å –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ —Ç–µ–∫—Å—Ç–∞
    if not ai_check_enabled:
        base_prompt = f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ—Ü–µ–Ω–∫–µ —Å—Ç—É–¥–µ–Ω—á–µ—Å–∫–∏—Ö —Ä–∞–±–æ—Ç.  
–û—Ü–µ–Ω–∏ —Ä–∞–±–æ—Ç—É —Å—Ç—Ä–æ–≥–æ, –ø–æ —Å—É—â–µ—Å—Ç–≤—É, –±–µ–∑ –ø–æ–±–ª–∞–∂–µ–∫, –Ω–æ —Å —É—á—ë—Ç–æ–º —É—á–µ–±–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è.  
–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—Å–µ–≥–¥–∞ –±–∏–Ω–∞—Ä–Ω—ã–π: "–∑–∞—á—Ç–µ–Ω–æ" –∏–ª–∏ "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ".  

–í–ê–ñ–ù–û: –í —ç—Ç–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ –ù–ï —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è —Ñ–∞–∫—Ç–æ—Ä AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. 
–°–æ—Å—Ä–µ–¥–æ—Ç–æ—á—å—Å—è –¢–û–õ–¨–ö–û –Ω–∞ –∫–∞—á–µ—Å—Ç–≤–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è, –ª–æ–≥–∏–∫–µ –∏–∑–ª–æ–∂–µ–Ω–∏—è –∏ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–∏.

–ö–†–ò–¢–ï–†–ò–ò –û–¶–ï–ù–ö–ò –ò–ó –®–ê–ë–õ–û–ù–ê:
{template_text}

–†–ê–ë–û–¢–ê –°–¢–£–î–ï–ù–¢–ê:
{text}

---

–ö–†–ò–¢–ï–†–ò–ò "–ó–ê–ß–¢–ï–ù–û":

–†–∞–±–æ—Ç–∞ –ø–æ–ª—É—á–∞–µ—Ç "–∑–∞—á—Ç–µ–Ω–æ", –µ—Å–ª–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –≤—Å–µ —É—Å–ª–æ–≤–∏—è:
1. –¢–µ–º–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —á—ë—Ç–∫–æ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∞ –∏ –∏–º–µ–µ—Ç —Å–º—ã—Å–ª.
2. –£–∫–∞–∑–∞–Ω–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è, —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ç–µ–º–æ–π.
3. –ï—Å—Ç—å —Ö–æ—Ç—è –±—ã –∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤—ã–±–æ—Ä–∞ —Ç–µ–º—ã.
4. –ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –æ–∂–∏–¥–∞–µ–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
5. –û–±—ä–µ–º —Ç–µ–∫—Å—Ç–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–µ –º–µ–Ω–µ–µ 60 —Å–ª–æ–≤ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è.
6. –¢–µ–∫—Å—Ç –ª–æ–≥–∏—á–µ–Ω, –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–µ–Ω –∏ —Ä–∞—Å–∫—Ä—ã–≤–∞–µ—Ç —Ç–µ–º—É.
7. –ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏—è.
8. –û—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º (—Å—Ç—Ä—É–∫—Ç—É—Ä–∞, —á–∏—Ç–∞–µ–º–æ—Å—Ç—å).

---

–ö–†–ò–¢–ï–†–ò–ò "–ù–ï –ó–ê–ß–¢–ï–ù–û":

–†–∞–±–æ—Ç–∞ –ø–æ–ª—É—á–∞–µ—Ç "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ", –µ—Å–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∏–∑ —É—Å–ª–æ–≤–∏–π:
1. –¢–µ–º–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –Ω–µ—è—Å–Ω–∞ –∏–ª–∏ –Ω–µ —Ä–∞—Å–∫—Ä—ã—Ç–∞.
2. –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏—è –≤—ã–±–æ—Ä–∞.
3. –¢–µ–∫—Å—Ç –Ω–µ–ª–æ–≥–∏—á–µ–Ω, –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤ –∏–ª–∏ –Ω–µ —Å–≤—è–∑–∞–Ω —Å –∑–∞—è–≤–ª–µ–Ω–Ω–æ–π —Ç–µ–º–æ–π.
4. –¢–µ–∫—Å—Ç —Å–æ—Å—Ç–æ–∏—Ç –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏–∑ –æ–±—â–∏—Ö —Ñ—Ä–∞–∑ –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏ –∏–ª–∏ —Ñ–∞–∫—Ç–æ–≤.
5. –û–±—ä–µ–º —Ç–µ–∫—Å—Ç–∞ –º–µ–Ω–µ–µ 50 —Å–ª–æ–≤.
6. –†–∞–±–æ—Ç–∞ –Ω–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–º—ã, —Ü–µ–ª–∏ –∏ –æ–∂–∏–¥–∞–µ–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
7. –ì—Ä—É–±—ã–µ –æ—à–∏–±–∫–∏ –≤ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–∏, –¥–µ–ª–∞—é—â–∏–µ —Ç–µ–∫—Å—Ç —Ç—Ä—É–¥–Ω–æ—á–∏—Ç–∞–µ–º—ã–º.

---

–ü–†–ê–í–ò–õ–ê –û–¶–ï–ù–ö–ò:

1. –ï—Å–ª–∏ –µ—Å—Ç—å —Å–æ–º–Ω–µ–Ω–∏–µ –º–µ–∂–¥—É "–∑–∞—á—Ç–µ–Ω–æ" –∏ "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ", –≤—ã–±–∏—Ä–∞–π "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ".
2. –ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∏ —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –Ω–µ —Å–Ω–∏–∂–∞—é—Ç –æ—Ü–µ–Ω–∫—É, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π.
3. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —Å–º—ã—Å–ª, –ª–æ–≥–∏–∫–∞, –ø–æ–ª–Ω–æ—Ç–∞ —Ä–∞—Å–∫—Ä—ã—Ç–∏—è —Ç–µ–º—ã, –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏—è.
4. –û—Ü–µ–Ω–∏–≤–∞–π –¢–û–õ–¨–ö–û –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –∏ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è, –ù–ï –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–æ–∏—Å—Ö–æ–∂–¥–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞.

---

–§–û–†–ú–ê–¢ –í–´–í–û–î–ê:

{{
  "result": "–∑–∞—á—Ç–µ–Ω–æ" –∏–ª–∏ "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ",
  "comment": "–∫—Ä–∞—Ç–∫–∏–π —Ä–∞–∑–±–æ—Ä —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è, –ª–æ–≥–∏—á–Ω–æ—Å—Ç–∏ –∏–∑–ª–æ–∂–µ–Ω–∏—è, –ø–æ–ª–Ω–æ—Ç—ã —Ä–∞—Å–∫—Ä—ã—Ç–∏—è —Ç–µ–º—ã, –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å—Ç—É–¥–µ–Ω—Ç—É"
}}

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
"""
    else:
        # –ü—Ä–æ–º–ø—Ç –¥–ª—è —Ä–µ–∂–∏–º–∞ –° AI –ø—Ä–æ–≤–µ—Ä–∫–æ–π
        base_prompt = f"""
–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ—Ü–µ–Ω–∫–µ —Å—Ç—É–¥–µ–Ω—á–µ—Å–∫–∏—Ö —Ä–∞–±–æ—Ç.  
–û—Ü–µ–Ω–∏ —Å—Ç—Ä–æ–≥–æ, –ø–æ —Å—É—â–µ—Å—Ç–≤—É, –±–µ–∑ –ø–æ–±–ª–∞–∂–µ–∫, –Ω–æ —Å —É—á—ë—Ç–æ–º —É—á–µ–±–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è.  
–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—Å–µ–≥–¥–∞ –±–∏–Ω–∞—Ä–Ω—ã–π: "–∑–∞—á—Ç–µ–Ω–æ" –∏–ª–∏ "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ".  
–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—Ä–∏–∑–Ω–∞–∫–∏ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤—Å—Ç—Ä–æ–µ–Ω–∞ –≤ –ª–æ–≥–∏–∫—É –æ—Ü–µ–Ω–∫–∏.

–û–¶–ï–ù–ö–ê –£–í–ï–†–ï–ù–ù–û–°–¢–ò –î–ï–¢–ï–ö–¢–û–†–ê AI:
‚Äî –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {ai_confidence or '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}.
‚Äî –í–ê–ñ–ù–û: –µ—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ù–ï ¬´–≤—ã—Å–æ–∫–∞—è¬ª, —Ñ–∞–∫—Ç –Ω–∞–ª–∏—á–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ AI –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º –¥–ª—è ¬´–Ω–µ –∑–∞—á—Ç–µ–Ω–æ¬ª. –£—á–∏—Ç—ã–≤–∞–π —Ç–æ–ª—å–∫–æ –ø—Ä–æ—á–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏.
‚Äî –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ¬´–≤—ã—Å–æ–∫–∞—è¬ª, —ç—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º–æ–µ –æ—Å–Ω–æ–≤–∞–Ω–∏–µ –¥–ª—è ¬´–Ω–µ –∑–∞—á—Ç–µ–Ω–æ¬ª –ø–æ –ø—Ä–∏–∑–Ω–∞–∫–∞–º AI (–ø—Ä–∏ –ø—Ä–æ—á–∏—Ö —Ä–∞–≤–Ω—ã—Ö).

–ö–†–ò–¢–ï–†–ò–ò –û–¶–ï–ù–ö–ò –ò–ó –®–ê–ë–õ–û–ù–ê:
{template_text}

–†–ê–ë–û–¢–ê –°–¢–£–î–ï–ù–¢–ê:
{text}

---

–ö–†–ò–¢–ï–†–ò–ò "–ó–ê–ß–¢–ï–ù–û":

–†–∞–±–æ—Ç–∞ –ø–æ–ª—É—á–∞–µ—Ç "–∑–∞—á—Ç–µ–Ω–æ", –µ—Å–ª–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –≤—Å–µ —É—Å–ª–æ–≤–∏—è:
1. –¢–µ–º–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —á—ë—Ç–∫–æ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∞ –∏ –∏–º–µ–µ—Ç —Å–º—ã—Å–ª.
2. –£–∫–∞–∑–∞–Ω–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è, —Å–≤—è–∑–∞–Ω–Ω–æ–µ —Å —Ç–µ–º–æ–π.
3. –ï—Å—Ç—å —Ö–æ—Ç—è –±—ã –∫—Ä–∞—Ç–∫–æ–µ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –≤—ã–±–æ—Ä–∞ —Ç–µ–º—ã.
4. –ü—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –æ–∂–∏–¥–∞–µ–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
5. –û–±—ä–µ–º —Ç–µ–∫—Å—Ç–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç –Ω–µ –º–µ–Ω–µ–µ 60 —Å–ª–æ–≤ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è.
6. –¢–µ–∫—Å—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–º—ã:
   - –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –ª–∏—á–Ω—ã–µ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è, –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã, –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—à–∏–±–∫–∏ –∏–ª–∏ –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø–µ—Ä–µ—Ö–æ–¥—ã;
   - —Å—Ç–∏–ª—å —Ç–µ–∫—Å—Ç–∞ –Ω–µ –≤—ã–≥–ª—è–¥–∏—Ç —à–∞–±–ª–æ–Ω–Ω—ã–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —ç–Ω—Ü–∏–∫–ª–æ–ø–µ–¥–∏—á–µ—Å–∫–∏–º –∏–ª–∏ –∏–¥–µ–∞–ª—å–Ω–æ –≥–ª–∞–¥–∫–∏–º.

---

–ö–†–ò–¢–ï–†–ò–ò "–ù–ï –ó–ê–ß–¢–ï–ù–û":

–†–∞–±–æ—Ç–∞ –ø–æ–ª—É—á–∞–µ—Ç "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ", –µ—Å–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∏–∑ —É—Å–ª–æ–≤–∏–π:
1. –¢–µ–º–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –Ω–µ—è—Å–Ω–∞.
2. –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∏–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏—è –≤—ã–±–æ—Ä–∞.
3. –¢–µ–∫—Å—Ç —Å–æ—Å—Ç–æ–∏—Ç –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏–∑ –æ–±—â–∏—Ö —Ñ—Ä–∞–∑ –±–µ–∑ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–∏ –∏–ª–∏ —Ñ–∞–∫—Ç–æ–≤.
4. –û–±—ä–µ–º —Ç–µ–∫—Å—Ç–∞ –º–µ–Ω–µ–µ 50 —Å–ª–æ–≤.
5. –¢–µ–∫—Å—Ç –∏–º–µ–µ—Ç –æ—á–µ–≤–∏–¥–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:
   - –∏–¥–µ–∞–ª—å–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ —Å—Ç–∏–ª—å –±–µ–∑ –æ—à–∏–±–æ–∫;
   - –ø–æ–≤—Ç–æ—Ä —Ç–∏–ø–∏—á–Ω—ã—Ö —Ñ—Ä–∞–∑ –≤—Ä–æ–¥–µ ¬´–ø–æ–≤—ã—à–µ–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏¬ª, ¬´—É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è¬ª;
   - –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ª–∏—á–Ω—ã—Ö –≤—ã—Å–∫–∞–∑—ã–≤–∞–Ω–∏–π, –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ –∏–ª–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫;
   - –º–æ–Ω–æ—Ç–æ–Ω–Ω—ã–π, –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π –∏–ª–∏ —ç–Ω—Ü–∏–∫–ª–æ–ø–µ–¥–∏—á–µ—Å–∫–∏–π —Å—Ç–∏–ª—å;
   - –≤—ã–≤–æ–¥—ã –∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∑–≤—É—á–∞—Ç –∫–∞–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã.
6. –†–∞–±–æ—Ç–∞ –Ω–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–º—ã, —Ü–µ–ª–∏ –∏ –æ–∂–∏–¥–∞–µ–º—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.

---

–ü–†–ê–í–ò–õ–ê –û–¶–ï–ù–ö–ò:

1. –ï—Å–ª–∏ –µ—Å—Ç—å —Å–æ–º–Ω–µ–Ω–∏–µ –º–µ–∂–¥—É "–∑–∞—á—Ç–µ–Ω–æ" –∏ "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ", –≤—ã–±–∏—Ä–∞–π "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ".
2. –û—Ä—Ñ–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∏ —Å—Ç–∏–ª–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –Ω–µ —Å–Ω–∏–∂–∞—é—Ç –æ—Ü–µ–Ω–∫—É, –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π –∏ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–π.
3. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —Å–º—ã—Å–ª, –ª–æ–≥–∏–∫–∞, —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ—Å—Ç—å.
4. –ù–∞–ª–∏—á–∏–µ —à–∞–±–ª–æ–Ω–Ω–æ—Å—Ç–∏, –∫–ª–∏—à–µ –∏–ª–∏ –±–µ–∑–ª–∏—á–Ω–æ–≥–æ –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–æ–≥–æ —Å—Ç–∏–ª—è ‚Äî –æ—Å–Ω–æ–≤–∞–Ω–∏–µ –¥–ª—è "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ".
5. –§–∞–∫—Ç AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —è–≤–ª—è–µ—Ç—Å—è –æ—Å–Ω–æ–≤–∞–Ω–∏–µ–º –¥–ª—è "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ" –¢–û–õ–¨–ö–û –ø—Ä–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ ¬´–≤—ã—Å–æ–∫–∞—è¬ª. –í –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö —ç—Ç–æ –Ω–µ –æ—Å–Ω–æ–≤–∞–Ω–∏–µ.

---

–§–û–†–ú–ê–¢ –í–´–í–û–î–ê:

{{
  "result": "–∑–∞—á—Ç–µ–Ω–æ" –∏–ª–∏ "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ",
  "comment": "–∫—Ä–∞—Ç–∫–∏–π —Ä–∞–∑–±–æ—Ä —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è, –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ü–∏–∏, —Å—Ç—Ä—É–∫—Ç—É—Ä—ã, –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å—Ç—É–¥–µ–Ω—Ç—É"
}}

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.
"""

    extra_instructions = room_prompt.strip()
    if extra_instructions:
        prompt = f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–∂–µ–ª–∞–Ω–∏—è –∫ –ø—Ä–æ–≤–µ—Ä–∫–µ:\n{extra_instructions}\n\n{base_prompt}"
    else:
        prompt = base_prompt

    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –≤–∞–ª–∏–¥–Ω—ã–π –æ—Ç–≤–µ—Ç
    response = await answer(client, text=text, prompt=prompt, models=models)
    if response:
        result = extract_binary_result(response)
        if result:
            logger.info("–ü–æ–ª—É—á–µ–Ω–∞ –±–∏–Ω–∞—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –æ—Ç –º–æ–¥–µ–ª–∏.")
            return result
        else:
            logger.warning("–û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω, –Ω–æ –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç.")
    else:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏.")

    return None


@retry(stop=stop_after_attempt(2), wait=wait_fixed(3),
       retry=retry_if_exception_type(Exception))
async def process_submission(
    json_obj: dict,
    template_text: str,
    client: GeminiClient,
    room_prompt: str = "",
    ai_check_enabled: bool = True,
) -> dict | None:
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω—É –ø–æ–¥–∞—á—É: –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–æ–≤,
    –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –µ–≥–æ –º–æ–¥–µ–ª–∏ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã.
    """
    user_dir = json_obj['user']
    file_path = json_obj['file_path']
    file_type = json_obj['file_type']
    
    try:
        # –ì–æ—Ç–æ–≤–∏–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ –∫–∞–∂–¥–æ–º—É —Ñ–∞–π–ª—É
        results_dir = os.path.join(user_dir, 'results')
        os.makedirs(results_dir, exist_ok=True)
        base_name = os.path.basename(file_path)
        safe_name = re.sub(r'[^a-zA-Z0-9_\-\.\u0400-\u04FF]+', '_', base_name)
        per_file_result = os.path.join(results_dir, f"{safe_name}.json")

        # –ï—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ ‚Äî –ø—Ä–æ–ø—É—Å—Ç–∏–º –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫—É
        if os.path.exists(per_file_result):
            logger.info(f"‚úÖ –£–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω —Ñ–∞–π–ª: {base_name}")
            async with aiofiles.open(per_file_result, 'r', encoding='utf-8') as f:
                try:
                    data = json.loads(await f.read())
                except Exception:
                    data = None
            return data
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
        if file_type == 'html':
            student_text = await extract_text_from_html(file_path)
        elif file_type in ['docx', 'doc']:
            student_text = await extract_text_from_word(file_path)
        elif file_type == 'pdf':
            student_text = await extract_text_from_pdf(file_path)
        else:
            logger.error(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {file_type}")
            return None
        
        if not student_text.strip():
            logger.warning(f"–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –≤ —Ñ–∞–π–ª–µ {file_path}")
            student_text = "–†–∞–±–æ—Ç–∞ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç–∞"
        elif len(student_text.strip()) < 70:
            logger.warning(f"–û—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç –≤ —Ñ–∞–π–ª–µ {file_path} ({len(student_text)} —Å–∏–º–≤–æ–ª–æ–≤)")
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –ø—Ä–æ—Å—Ç–æ —à–∞–±–ª–æ–Ω–æ–º
            if "—à–∞–±–ª–æ–Ω" in student_text.lower() or "template" in student_text.lower():
                student_text = "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω —Ç–æ–ª—å–∫–æ —à–∞–±–ª–æ–Ω –±–µ–∑ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è"
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–º –æ–±—ä–µ–º–µ
                student_text = f"–¢–ï–ö–°–¢ –°–õ–ò–®–ö–û–ú –ö–û–†–û–¢–ö–ò–ô ({len(student_text)} —Å–∏–º–≤–æ–ª–æ–≤): {student_text}"
        
        logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω —Ç–µ–∫—Å—Ç –∏–∑ {file_path} ({len(student_text)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ AI –ø—Ä–æ–≤–µ—Ä–∫–∞
        ai_check = None
        ai_confidence = None
        if ai_check_enabled:
            ai_check = await check_ai_generation(client, student_text)
            if ai_check:
                ai_confidence = ai_check.get('confidence')
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –±–∞–∑–æ–≤–æ–π –æ—Ü–µ–Ω–∫–∏ –æ—Ç AI —Å —É—á–µ—Ç–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
        # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –æ—Ñ–ª–∞–π–Ω-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: –µ—Å–ª–∏ DUMMY_EVAL=true ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é –æ—Ü–µ–Ω–∫—É
        if os.environ.get('DUMMY_EVAL', '').lower() in {'1', 'true', 'yes'}:
            clean_len = len(re.sub(r'\s+', ' ', student_text).strip())
            evaluation = {
                "result": "–∑–∞—á—Ç–µ–Ω–æ" if clean_len >= 400 else "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ",
                "comment": f"–†–µ–∂–∏–º DUMMY_EVAL: –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ {clean_len} —Å–∏–º–≤–æ–ª–æ–≤. –ü–æ—Ä–æ–≥ 400."
            }
        else:
            evaluation = await get_binary_evaluation(
                client,
                student_text,
                template_text,
                room_prompt=room_prompt,
                ai_confidence=ai_confidence,
                ai_check_enabled=ai_check_enabled,
            )
        
        if not evaluation:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ü–µ–Ω–∫—É –¥–ª—è {user_dir}")
            evaluation = {
                "result": "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ",
                "comment": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ü–µ–Ω–∫–∏ –æ—Ç AI"
            }
        
        # –ñ—ë—Å—Ç–∫–æ–µ –ø—Ä–∞–≤–∏–ª–æ: –Ω–µ–∑–∞—á–µ—Ç –∑–∞ AI —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ AI –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤–∫–ª—é—á–µ–Ω–∞)
        if ai_check_enabled and ai_check and ai_check.get('ai_detected', False):
            if ai_check.get('confidence') == '–≤—ã—Å–æ–∫–∞—è':
                evaluation = {
                    "result": "–Ω–µ –∑–∞—á—Ç–µ–Ω–æ",
                    "comment": evaluation.get('comment', '') + "\n\n–ü—Ä–∏—á–∏–Ω–∞: –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ü–∏–∏ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."
                }
            else:
                # –ú—è–≥–∫–æ–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ ‚Äî –Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ –∏—Ç–æ–≥
                evaluation['comment'] = evaluation.get('comment', '') + "\n\n–ó–ê–ú–ï–ß–ê–ù–ò–ï: –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–µ –≤—ã—Å–æ–∫–∞—è)."
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ per-file JSON
        result_data = {
            "student": os.path.basename(user_dir),
            "file": os.path.basename(file_path),
            "date": time.strftime('%Y-%m-%d %H:%M:%S'),
            "result": evaluation['result'],
            "comment": evaluation['comment'],
            "ai_detection": ai_check if ai_check else None,
            "checked_by": "SFEDU"
        }

        result_content = json.dumps(result_data, ensure_ascii=False, indent=2)
        async with aiofiles.open(per_file_result, 'w', encoding='utf-8') as f:
            await f.write(result_content)
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {per_file_result}")

        return {
            "student": os.path.basename(user_dir),
            "file": os.path.basename(file_path),
            "result": evaluation['result'],
            "comment": evaluation['comment'],
            "result_file": per_file_result
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ–¥–∞—á–∏ {user_dir}: {e}")
        return None


async def find_all_submissions(root_dir: str) -> list:
    """
    –û–±—Ö–æ–¥–∏—Ç –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤—Å–µ—Ö –ø–æ–¥–∞—á –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.
    """
    res = []
    
    for path, _, files in os.walk(root_dir):
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        if path == root_dir:
            continue
            
        # –ò—â–µ–º —Ñ–∞–π–ª—ã –∑–∞–¥–∞–Ω–∏–π
        for file in files:
            if file.endswith(('.docx', '.doc')):
                res.append({
                    'user': path,
                    'file_path': os.path.join(path, file),
                    'file_type': 'docx' if file.endswith('.docx') else 'doc'
                })
            elif file == 'onlinetext.html':
                res.append({
                    'user': path,
                    'file_path': os.path.join(path, file),
                    'file_type': 'html'
                })
            elif file.lower().endswith('.pdf'):
                res.append({
                    'user': path,
                    'file_path': os.path.join(path, file),
                    'file_type': 'pdf'
                })
    
    logger.info(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥–∞—á: {len(res)}")
    return res


@retry(stop=stop_after_attempt(2), wait=wait_fixed(3),
       retry=retry_if_exception_type(Exception))
def process_all_submissions(
    json_user_files: List[dict],
    template_text: str,
    client: GeminiClient,
    room_prompt: str = "",
    ai_check_enabled: bool = True,
    progress_callback: Callable[[str, int, int], None] | None = None,
):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –ø–æ–¥–∞—á–∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –≤—ã–ø–æ–ª–Ω—è–µ–º—ã—Ö –∑–∞–¥–∞—á.
    """
    semaphore = threading.Semaphore(1)  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–æ 1 –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞ –¥–ª—è –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ API
    results = []
    results_lock = threading.Lock()
    progress_lock = threading.Lock()
    total_items = len(json_user_files)
    completed = 0

    progress_bar = None
    if progress_callback is None and total_items:
        progress_bar = tqdm(total=total_items, desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–¥–∞—á")
    elif progress_callback is not None:
        progress_callback("processing_submissions", 0, total_items)

    def worker(submission, template_text, client, room_prompt, ai_check_enabled):
        nonlocal results, completed
        semaphore.acquire()
        try:
            # –°–æ–∑–¥–∞—ë–º –Ω–æ–≤—ã–π —Ü–∏–∫–ª —Å–æ–±—ã—Ç–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Ç–æ–∫–∞
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(
                process_submission(submission, template_text, client, room_prompt, ai_check_enabled),
            )
            loop.close()
            with results_lock:
                results.append(result)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–æ–¥–∞—á–∏ {submission.get('user')}: {e}")
            with results_lock:
                results.append(None)
        finally:
            if progress_bar is not None:
                progress_bar.update(1)
            with progress_lock:
                completed += 1
                current_completed = completed
            if progress_callback is not None:
                progress_callback("processing_submissions", current_completed, total_items)
            semaphore.release()

    threads = []

    for submission in json_user_files:
        thread = Thread(target=worker, args=(submission, template_text, client, room_prompt, ai_check_enabled))
        thread.start()
        threads.append(thread)

    # –û–∂–∏–¥–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –ø–æ—Ç–æ–∫–æ–≤
    for thread in threads:
        thread.join()

    if progress_bar is not None:
        progress_bar.close()
    logger.info("–í—Å–µ –ø–æ–¥–∞—á–∏ –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.")
    return results


async def generate_final_summary(root_dir: str):
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤—É—é –≤–µ–¥–æ–º–æ—Å—Ç—å –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
    """
    res = []
    dedup_records = {}
    
    for path, _, files in os.walk(root_dir):
        if path == root_dir:
            continue

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ per-file —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        candidates = []
        results_dir = os.path.join(path, 'results')
        if os.path.isdir(results_dir):
            for entry in os.listdir(results_dir):
                if not entry.lower().endswith('.json'):
                    continue
                result_file = os.path.join(results_dir, entry)
                try:
                    async with aiofiles.open(result_file, 'r', encoding='utf-8') as f:
                        content = await f.read()
                    data = json.loads(content)
                    student_name = data.get('student', os.path.basename(path))
                    result = data.get('result', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ')
                    comment = data.get('comment', '–Ω–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è')
                    date_str = data.get('date')

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–ª–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–µ—Ç–µ–∫—Ü–∏–∏ AI
                    ai_detection = data.get('ai_detection')
                    if ai_detection:
                        ai_detected = ai_detection.get('ai_detected', False)
                        ai_confidence = ai_detection.get('confidence', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                        ai_reasons = ai_detection.get('reasons', [])
                        ai_comment = ai_detection.get('comment', '')

                        if ai_detected:
                            ai_status = f"–î–∞ ({ai_confidence})"
                            if ai_comment:
                                ai_details_value = ai_comment.strip()
                            elif ai_reasons:
                                ai_details_value = f"–ü—Ä–∏—á–∏–Ω—ã: {'; '.join(ai_reasons)}"
                            else:
                                ai_details_value = "–ü—Ä–∏–∑–Ω–∞–∫–∏ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω—ã"
                        else:
                            ai_status = "–ù–µ—Ç"
                            if ai_comment:
                                ai_details_value = ai_comment.strip()
                            else:
                                ai_details_value = "–ü—Ä–∏–∑–Ω–∞–∫–∏ AI-–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã"
                    else:
                        ai_status = "–ù–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ"
                        ai_details_value = "–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω—è–ª–∞—Å—å"

                except json.JSONDecodeError:
                    # Fallback –¥–ª—è —Å—Ç–∞—Ä–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞
                    student_name = os.path.basename(path)
                    result_match = re.search(r'–†–ï–ó–£–õ–¨–¢–ê–¢: (.+)', content)
                    result = result_match.group(1).strip() if result_match else "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ"
                    comment_match = re.search(r'–ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô:\s*(.+?)(?=\n\n|\Z)', content, re.DOTALL)
                    comment = comment_match.group(1).strip() if comment_match else "–Ω–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è"
                    ai_status = "–ù–µ –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ"
                    ai_details_value = "–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ –≤—ã–ø–æ–ª–Ω—è–ª–∞—Å—å"
                    date_str = None

                # –°–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ (–Ω–µ –ø–æ–ø–∞–¥—É—Ç –≤ –∏—Ç–æ–≥–æ–≤—ã–π Excel)
                # 1) –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å ID –∏–∑ –∏–º–µ–Ω–∏ —Å—Ç—É–¥–µ–Ω—Ç–∞/–∫–∞—Ç–∞–ª–æ–≥–∞
                raw_student = student_name or os.path.basename(path)
                folder_name = os.path.basename(path)
                student_id = None
                # –û—Å–Ω–æ–≤–Ω–æ–π —à–∞–±–ª–æ–Ω Moodle: –§–ò–û_–ò–î_assignsubmission_<—Ç–∏–ø>
                m = re.match(r'^(.+?)_(\d+)_assignsubmission_(\w+)$', raw_student)
                if m:
                    student_id = m.group(2)
                else:
                    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã ID –≤ —Ç–µ–∫—Å—Ç–µ
                    m = re.search(r'ID[:=]\s*(\w{3,})', raw_student)
                    if not m:
                        m = re.search(r'\[(?:id|ID)=(\w+)\]', raw_student)
                    if m:
                        student_id = m.group(1)
                if not student_id:
                    # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑ –∏–º–µ–Ω–∏ –ø–∞–ø–∫–∏
                    m = re.match(r'^(.+?)_(\d+)_assignsubmission_(\w+)$', folder_name)
                    if m:
                        student_id = m.group(2)

                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –§–ò–û –¥–ª—è –∫–ª—é—á–∞
                try:
                    import unicodedata
                    normalized_student = unicodedata.normalize('NFC', str(raw_student).strip()).casefold()
                except Exception:
                    normalized_student = str(raw_student).strip().lower()

                # –ü–∞—Ä—Å –¥–∞—Ç—ã/mtime –∫–∞–∫ fallback
                from datetime import datetime
                parsed_date = None
                if date_str:
                    try:
                        parsed_date = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')
                    except Exception:
                        parsed_date = None
                try:
                    mtime = os.path.getmtime(result_file)
                except Exception:
                    mtime = 0.0

                    # –ö–ª—é—á –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
                    key = student_id if student_id else normalized_student

                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø–∏—Å—å —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –ø–æ–ª—è–º–∏ (–∫–∞–Ω–¥–∏–¥–∞—Ç)
                    record = {
                        '–°—Ç—É–¥–µ–Ω—Ç': raw_student,
                        '–†–µ–∑—É–ª—å—Ç–∞—Ç': result,
                        'AI-–¥–µ—Ç–µ–∫—Ü–∏—è': ai_status,
                        'AI-–¥–µ—Ç–∞–ª–∏': ai_details_value,
                        '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π': comment,
                        '–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É': result_file,
                        '__student_id__': student_id,
                        '__normalized_student__': normalized_student,
                        '__parsed_date__': parsed_date,
                        '__mtime__': mtime,
                    }
                    candidates.append((key, record))
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ {result_file}: {e}")

        # –¢–∞–∫–∂–µ —É—á–∏—Ç—ã–≤–∞–µ–º legacy result.txt (–µ—Å–ª–∏ –æ–Ω –±—ã–ª —Ä–∞–Ω–µ–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –ª–æ–≥–∏–∫–æ–π –¥–æ –º–Ω–æ–≥–æ–¥–æ–∫–æ–≤–æ–≥–æ —Ä–µ–∂–∏–º–∞)
        legacy_result = os.path.join(path, 'result.txt')
        if os.path.exists(legacy_result):
            try:
                async with aiofiles.open(legacy_result, 'r', encoding='utf-8') as f:
                    content = await f.read()
                data = json.loads(content)
                raw_student = data.get('student', os.path.basename(path))
                result = data.get('result', '–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ')
                comment = data.get('comment', '–Ω–µ—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è')
                date_str = data.get('date')
                ai_status = data.get('ai_detection', {}).get('ai_detected', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ') if isinstance(data.get('ai_detection'), dict) else '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'

                folder_name = os.path.basename(path)
                # –ü–æ–∏—Å–∫ ID —Å—Ç—É–¥–µ–Ω—Ç–∞
                student_id = None
                m = re.match(r'^(.+?)_(\d+)_assignsubmission_(\w+)$', raw_student)
                if m:
                    student_id = m.group(2)
                if not student_id:
                    m = re.match(r'^(.+?)_(\d+)_assignsubmission_(\w+)$', folder_name)
                    if m:
                        student_id = m.group(2)

                try:
                    import unicodedata
                    normalized_student = unicodedata.normalize('NFC', str(raw_student).strip()).casefold()
                except Exception:
                    normalized_student = str(raw_student).strip().lower()

                from datetime import datetime
                parsed_date = None
                if date_str:
                    try:
                        parsed_date = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')
                    except Exception:
                        parsed_date = None
                try:
                    mtime = os.path.getmtime(legacy_result)
                except Exception:
                    mtime = 0.0

                key = student_id if student_id else normalized_student
                record = {
                    '–°—Ç—É–¥–µ–Ω—Ç': raw_student,
                    '–†–µ–∑—É–ª—å—Ç–∞—Ç': result,
                    'AI-–¥–µ—Ç–µ–∫—Ü–∏—è': ai_status,
                    'AI-–¥–µ—Ç–∞–ª–∏': 'legacy result.txt',
                    '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π': comment,
                    '–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É': legacy_result,
                    '__student_id__': student_id,
                    '__normalized_student__': normalized_student,
                    '__parsed_date__': parsed_date,
                    '__mtime__': mtime,
                }
                candidates.append((key, record))
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ legacy result.txt: {e}")

        # –ï—Å–ª–∏ –Ω–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ ‚Äî –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–π –ø–∞–ø–∫–µ
        if not candidates:
            continue

        # –í—ã–±–æ—Ä –ª—É—á—à–µ–π –∑–∞–ø–∏—Å–∏ –ø–æ –∫–ª—é—á—É —Å—Ç—É–¥–µ–Ω—Ç–∞
        def record_priority(rec):
            is_pass = 1 if str(rec.get('–†–µ–∑—É–ª—å—Ç–∞—Ç', '')).strip().lower() == '–∑–∞—á—Ç–µ–Ω–æ' else 0
            dt = rec.get('__parsed_date__')
            ts = dt.timestamp() if dt else rec.get('__mtime__', 0.0)
            comment_len = len(str(rec.get('–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π', '')))
            return (is_pass, ts, comment_len)

        for key, record in candidates:
            best = dedup_records.get(key)
            if best is None or record_priority(record) > record_priority(best):
                dedup_records[key] = record

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞—Ç–Ω–æ –≤ result.txt
        for key, record in dedup_records.items():
            if record.get('–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É', '').startswith(path):
                result_file_path = os.path.join(path, 'result.txt')
                aggregate = {
                    "student": record.get('–°—Ç—É–¥–µ–Ω—Ç'),
                    "result": record.get('–†–µ–∑—É–ª—å—Ç–∞—Ç'),
                    "comment": record.get('–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π'),
                    "date": time.strftime('%Y-%m-%d %H:%M:%S'),
                    "ai_detection": None,
                }
                try:
                    async with aiofiles.open(result_file_path, 'w', encoding='utf-8') as f:
                        await f.write(json.dumps(aggregate, ensure_ascii=False, indent=2))
                except Exception as e:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–π result.txt: {e}")

    # –§–∏–Ω–∞–ª–∏–∑–∞—Ü–∏—è: —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–ø–∏—Å–µ–π –∏ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ 6 –∫–æ–ª–æ–Ω–æ–∫
    final_records = list(dedup_records.values())
    final_records.sort(key=lambda row: str(row.get('–°—Ç—É–¥–µ–Ω—Ç', '')).casefold())
    columns = ['–°—Ç—É–¥–µ–Ω—Ç', '–†–µ–∑—É–ª—å—Ç–∞—Ç', 'AI-–¥–µ—Ç–µ–∫—Ü–∏—è', 'AI-–¥–µ—Ç–∞–ª–∏', '–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π', '–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É']
    df = pd.DataFrame([{k: rec.get(k) for k in columns} for rec in final_records], columns=columns)
    summary_path = os.path.join(root_dir, f'–ò—Ç–æ–≥–æ–≤–∞—è_–≤–µ–¥–æ–º–æ—Å—Ç—å_{os.path.basename(root_dir)}.xlsx')
    df.to_excel(summary_path, index=False)
    
    # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Excel —Ñ–∞–π–ª–∞
    try:
        from openpyxl import load_workbook
        from openpyxl.styles import Alignment, PatternFill
        from openpyxl.utils import get_column_letter
        
        wb = load_workbook(summary_path)
        ws = wb.active
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç–∏–ª–µ–π
        header_fill = PatternFill(start_color="87CEEB", end_color="87CEEB", fill_type="solid")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —à–∏—Ä–∏–Ω—ã —Å—Ç–æ–ª–±—Ü–æ–≤ –∏ —Å—Ç–∏–ª–µ–π
        for col_idx, column_cells in enumerate(ws.iter_cols(min_row=1, max_row=1, min_col=1, max_col=ws.max_column), start=1):
            max_length = max(len(str(cell.value)) if cell.value else 0 for cell in column_cells)
            adjusted_width = max_length + 2
            column_letter = get_column_letter(col_idx)
            ws.column_dimensions[column_letter].width = adjusted_width
            for cell in column_cells:
                cell.fill = header_fill
                cell.alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø–µ—Ä–µ–Ω–æ—Å–∞ —Ç–µ–∫—Å—Ç–∞ –∫–æ –≤—Å–µ–º —è—á–µ–π–∫–∞–º
        for row in ws.iter_rows(min_row=2, max_row=ws.max_row, min_col=1, max_col=ws.max_column):
            for cell in row:
                cell.alignment = Alignment(wrap_text=True)
        
        wb.save(summary_path)
        logger.info(f"–ò—Ç–æ–≥–æ–≤–∞—è –≤–µ–¥–æ–º–æ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {summary_path}")
        
    except Exception as e:
        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å Excel —Ñ–∞–π–ª: {e}")
    
    return df, summary_path


async def check_processed_students(root_dir: str, json_user_files: list) -> tuple:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–∫–æ–ª—å–∫–æ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ.
    """
    processed_count = 0
    
    for submission in json_user_files:
        user_dir = submission['user']
        result_file = os.path.join(user_dir, 'result.txt')
        
        if os.path.exists(result_file):
            processed_count += 1
    
    return processed_count, 0  # –í—Ç–æ—Ä–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏


async def run_auto_checker_async(
    root_dir: str,
    template_path: str,
    room_prompt: str = "",
    ai_check_enabled: bool = True,
    progress_callback: Callable[[str, int, int], None] | None = None,
) -> tuple[pd.DataFrame | None, str | None]:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame –∏ –ø—É—Ç—å –∫ –≤–µ–¥–æ–º–æ—Å—Ç–∏."""

    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ %s", root_dir)
    logger.info("AI –ø—Ä–æ–≤–µ—Ä–∫–∞: %s", "–≤–∫–ª—é—á–µ–Ω–∞" if ai_check_enabled else "–æ—Ç–∫–ª—é—á–µ–Ω–∞")

    if not os.path.exists(template_path):
        raise FileNotFoundError(f"–§–∞–π–ª —à–∞–±–ª–æ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {template_path}")

    try:
        template_text = await extract_text_from_word(template_path)
        if not template_text.strip():
            template_text = "–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã. –û—Ü–µ–Ω–∏—Ç–µ —Ä–∞–±–æ—Ç—É –ø–æ –æ–±—â–∏–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º."
            logger.warning("–®–∞–±–ª–æ–Ω –ø—É—Å—Ç–æ–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è.")
    except Exception as exc:  # noqa: BLE001
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —à–∞–±–ª–æ–Ω: %s", exc)
        template_text = "–ö—Ä–∏—Ç–µ—Ä–∏–∏ –æ—Ü–µ–Ω–∫–∏ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã. –û—Ü–µ–Ω–∏—Ç–µ —Ä–∞–±–æ—Ç—É –ø–æ –æ–±—â–∏–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º."

    json_user_files = await find_all_submissions(root_dir)
    if not json_user_files:
        logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–æ–¥–∞—á–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ %s", root_dir)
        return None, None

    total_submissions = len(json_user_files)
    if progress_callback is not None:
        progress_callback("collecting_submissions", 0, total_submissions)

    processed_count, _ = await check_processed_students(root_dir, json_user_files)
    remaining_count = len(json_user_files) - processed_count

    logger.info(
        "–í—Å–µ–≥–æ —Ä–∞–±–æ—Ç: %s, –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ä–∞–Ω–µ–µ: %s, –æ—Å—Ç–∞–ª–æ—Å—å: %s",
        len(json_user_files),
        processed_count,
        remaining_count,
    )

    client = GeminiClient()
    process_all_submissions(
        json_user_files,
        template_text,
        client,
        room_prompt=room_prompt,
        ai_check_enabled=ai_check_enabled,
        progress_callback=progress_callback,
    )

    if progress_callback is not None:
        progress_callback("generating_summary", 0, 1)
    df, summary_path = await generate_final_summary(root_dir)
    if progress_callback is not None:
        progress_callback("generating_summary", 1, 1)
        progress_callback("finished", total_submissions, total_submissions)
    logger.info("–ò—Ç–æ–≥–æ–≤–∞—è –≤–µ–¥–æ–º–æ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: %s", summary_path)
    return df, summary_path


def run_auto_checker(
    root_dir: str,
    template_path: str,
    room_prompt: str = "",
    ai_check_enabled: bool = True,
    progress_callback: Callable[[str, int, int], None] | None = None,
) -> str | None:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ñ–∞—Å–∞–¥ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑ –≤–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è."""

    _df, summary_path = asyncio.run(
        run_auto_checker_async(
            root_dir,
            template_path,
            room_prompt=room_prompt,
            ai_check_enabled=ai_check_enabled,
            progress_callback=progress_callback,
        ),
    )
    return summary_path


async def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö —Å—Ç—É–¥–µ–Ω—Ç–æ–≤.
    """
    print("üöÄ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–¥–∞–Ω–∏–π —Å—Ç—É–¥–µ–Ω—Ç–æ–≤")
    print("=" * 50)
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –ø—É—Ç–∏
    template_path = "–®–∞–±–ª–æ–Ω.docx"
    root_dir = "–ü—Ä–∏–º–µ—Ä—ã"
    
    print(f"üìÑ –®–∞–±–ª–æ–Ω: {template_path}")
    print(f"üìÅ –ü–∞–ø–∫–∞ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {root_dir}")
    
    if not os.path.exists(template_path):
        logger.error(f"–§–∞–π–ª —à–∞–±–ª–æ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω: {template_path}")
        print("üí° –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª —à–∞–±–ª–æ–Ω–∞ —Å –∫—Ä–∏—Ç–µ—Ä–∏—è–º–∏ –æ—Ü–µ–Ω–∫–∏")
        return
    
    if not os.path.exists(root_dir):
        logger.error(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {root_dir}")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø–∞–ø–∫–∞ —Å —Ä–∞–±–æ—Ç–∞–º–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
        return
    
    df, summary_path = await run_auto_checker_async(root_dir, template_path)
    if df is None or summary_path is None:
        logger.info("–ü—Ä–æ—Ü–µ—Å—Å –∑–∞–≤–µ—Ä—à—ë–Ω –±–µ–∑ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –≤–µ–¥–æ–º–æ—Å—Ç–∏.")
    else:
        logger.info("‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û—Ç—á—ë—Ç: %s", summary_path)


if __name__ == "__main__":
    print("üöÄ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–¥–∞–Ω–∏–π —Å Gemini API (Word/HTML)")
    print(f"üìä –î–æ—Å—Ç—É–ø–Ω–æ –∫–ª—é—á–µ–π: {len(API_KEYS)}")
    print("‚ö° –ó–∞–¥–µ—Ä–∂–∫–∏: 10-20 —Å–µ–∫—É–Ω–¥")
    print("üîÑ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è —Ä–æ—Ç–∞—Ü–∏—è –∫–ª—é—á–µ–π –ø—Ä–∏ –∫–≤–æ—Ç–∞—Ö")
    print("üìù –ë–∏–Ω–∞—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: –∑–∞—á—Ç–µ–Ω–æ/–Ω–µ –∑–∞—á—Ç–µ–Ω–æ")
    print("üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ result.txt")
    print("=" * 60)
    
    asyncio.run(main())
